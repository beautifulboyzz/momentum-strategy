import streamlit as st
import pandas as pd
import numpy as np
import os
import plotly.express as px
import plotly.graph_objects as go
import unicodedata
from datetime import datetime, timedelta

# ================= 1. ç³»ç»Ÿé…ç½® =================
st.set_page_config(page_title="Dual Momentumå›æµ‹ç³»ç»Ÿ", layout="wide", page_icon="")

# --- è·¯å¾„è‡ªåŠ¨é€‚é…é€»è¾‘ ---
local_absolute_path = r"D:\SARæ—¥é¢‘\å…¨éƒ¨å“ç§æ—¥çº¿"

if os.path.exists(local_absolute_path):
    DEFAULT_DATA_FOLDER = local_absolute_path
else:
    DEFAULT_DATA_FOLDER = "data"


# ================= 2. æ•°æ®å¤„ç† =================

def read_robust_csv(f):
    """
    é€šç”¨CSVè¯»å–å‡½æ•° (æ”¯æŒ gbk å’Œ utf-8)
    """
    for enc in ['gbk', 'utf-8', 'gb18030']:
        try:
            df = pd.read_csv(f, encoding=enc)
            cols = [str(c).strip() for c in df.columns]
            rename_map = {}

            # æ¨¡ç³ŠåŒ¹é…åˆ—å
            for c in df.columns:
                c_str = str(c).strip()
                if c_str in ['æ—¥æœŸ', 'æ—¥æœŸ/æ—¶é—´', 'date', 'Date']: rename_map[c] = 'date'
                if c_str in ['æ”¶ç›˜ä»·', 'æ”¶ç›˜', 'close', 'price', 'Close']: rename_map[c] = 'close'
                if c_str in ['æœ€é«˜ä»·', 'æœ€é«˜', 'high', 'High']: rename_map[c] = 'high'
                if c_str in ['æœ€ä½ä»·', 'æœ€ä½', 'low', 'Low']: rename_map[c] = 'low'

            df.rename(columns=rename_map, inplace=True)

            if 'date' in df.columns and 'close' in df.columns:
                return df
        except:
            continue
    return None


@st.cache_data(ttl=3600)
def load_data_and_calc_atr(folder, atr_window=20):
    """
    è¯»å–æ•°æ® (å« ATR è®¡ç®—å’Œ Low ä»·æ ¼è¯»å–)
    """
    if not os.path.exists(folder):
        return None, None, None, f"è·¯å¾„ä¸å­˜åœ¨: {folder}"

    # ã€æ ¸å¿ƒä¿ç•™ã€‘å¿…é¡»æ’åºï¼Œä¿è¯ Linux/Windows è¯»å–é¡ºåºä¸€è‡´
    files = sorted([f for f in os.listdir(folder) if f.endswith('.csv')])
    
    if not files:
        return None, None, None, f"åœ¨ {folder} ä¸­æœªæ‰¾åˆ°CSVæ–‡ä»¶"

    price_dict = {}
    vol_dict = {}
    low_dict = {}
    
    progress_bar = st.progress(0, text="æ­£åœ¨åŠ è½½æ•°æ®...")

    for i, file in enumerate(files):
        # ã€æ ¸å¿ƒä¿ç•™ã€‘æ–‡ä»¶åæ ‡å‡†åŒ–ï¼Œé˜²æ­¢è·¨å¹³å°ç¼–ç é—®é¢˜
        file_norm = unicodedata.normalize('NFC', file)
        
        # å‰”é™¤é€»è¾‘
        if "çº¤ç»´æ¿" in file_norm or "èƒ¶åˆæ¿" in file_norm or "çº¿æ" in file_norm:
            continue

        name = file_norm.split('.')[0].replace("ä¸»è¿", "").replace("æ—¥çº¿", "")
        path = os.path.join(folder, file)

        df = read_robust_csv(path)
        if df is None: continue

        try:
            df['date'] = pd.to_datetime(df['date'], errors='coerce')
            df.dropna(subset=['date', 'close', 'high', 'low'], inplace=True)
            df['date'] = df['date'].dt.normalize()
            
            # ã€æ ¸å¿ƒä¿ç•™ã€‘å†æ¬¡æ’åºç¡®ä¿æ—¶é—´åºåˆ—æ­£ç¡®
            df.sort_values('date', inplace=True)
            
            # å»é‡
            df = df[~df.index.duplicated(keep='last')]
            df.set_index('date', inplace=True)

            # --- è®¡ç®— ATR/NATR ---
            prev_close = df['close'].shift(1)
            tr1 = df['high'] - df['low']
            tr2 = (df['high'] - prev_close).abs()
            tr3 = (df['low'] - prev_close).abs()
            tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)

            atr = tr.rolling(atr_window).mean()
            natr = atr / df['close']

            price_dict[name] = df['close']
            vol_dict[name] = natr
            low_dict[name] = df['low']

        except Exception as e:
            continue

        if i % 10 == 0:
            progress_bar.progress((i + 1) / len(files), text=f"åŠ è½½: {name}")

    progress_bar.empty()

    if not price_dict:
        return None, None, None, "æœªè¯»å–åˆ°æœ‰æ•ˆæ•°æ®ï¼Œè¯·æ£€æŸ¥CSVæ ¼å¼"

    # åˆå¹¶ä¸ºå®½è¡¨
    df_prices = pd.DataFrame(price_dict).sort_index().ffill()
    df_vols = pd.DataFrame(vol_dict).sort_index().ffill()
    df_lows = pd.DataFrame(low_dict).sort_index().ffill()

    return df_prices, df_vols, df_lows, None


# ================= 3. æ ¸å¿ƒç­–ç•¥é€»è¾‘ =================

def run_strategy_logic(df_prices, df_vols, df_lows, params):
    """
    æ ¸å¿ƒç­–ç•¥é€»è¾‘
    """
    lookback_short = params['short']
    lookback_long = params['long']
    hold_num = params['hold_num']
    filter_ma = params['ma']
    stop_loss_pct = params['stop_loss_pct']

    start_date = pd.to_datetime(params['start_date'])
    end_date = pd.to_datetime(params['end_date'])

    # --- A. å› å­è®¡ç®— ---
    mom_short = df_prices.pct_change(lookback_short)
    mom_long = df_prices.pct_change(lookback_long)
    momentum_score = 0.4 * mom_short + 0.6 * mom_long
    ma_filter = df_prices > df_prices.rolling(filter_ma).mean()
    asset_daily_rets = df_prices.pct_change().fillna(0)

    # --- B. åˆå§‹åŒ– ---
    capital = 1.0
    nav_record = []
    asset_contribution = {}
    logs = []

    full_dates = df_prices.index
    try:
        start_idx_loc = full_dates.get_indexer([start_date], method='bfill')[0]
    except:
        start_idx_loc = 0

    min_idx = max(lookback_long, filter_ma, 20)
    start_idx_loc = max(start_idx_loc, min_idx)

    if start_idx_loc >= len(full_dates):
        return pd.DataFrame(), pd.DataFrame(), ["é€‰å®šæ—¶é—´å†…æ•°æ®ä¸è¶³"]

    weights = {}
    curr_holdings = {}
    entry_prices = {}
    log_buffer_pnl = []
    cycle_count = 1
    log_start_date = full_dates[start_idx_loc]

    # --- C. æŒ‰æ—¥å¾ªç¯ ---
    for i in range(start_idx_loc, len(full_dates)):
        curr_date = full_dates[i]
        if curr_date > end_date: break
        prev_date = full_dates[i - 1]

        # 1. æ¯æ—¥é€‰è‚¡
        try:
            scores = momentum_score.loc[prev_date].dropna()
            vols = df_vols.loc[prev_date]

            if len(scores) < hold_num:
                weights = {}
            else:
                top = scores.sort_values(ascending=False).head(hold_num).index.tolist()
                valid = [a for a in top if ma_filter.loc[prev_date, a]]

                if not valid:
                    weights = {}
                else:
                    sub_vols = vols[valid]
                    inv = 1.0 / (sub_vols + 1e-6)
                    weights = (inv / inv.sum()).to_dict()

            entry_prices = {a: df_prices.loc[prev_date, a] for a in weights.keys()}
            curr_holdings = weights.copy()

        except KeyError:
            weights = {}
            curr_holdings = {}

        # 2. ç»“ç®—ä¸é£æ§
        daily_pnl = 0.0
        stopped_assets = []

        for asset, w in list(curr_holdings.items()):
            if w == 0: continue

            today_low = df_lows.loc[curr_date, asset]
            ref_price = entry_prices.get(asset, df_prices.loc[curr_date, asset])

            if ref_price > 0 and (today_low / ref_price - 1) < -stop_loss_pct:
                actual_ret = -stop_loss_pct
                daily_pnl += w * actual_ret
                asset_contribution[asset] = asset_contribution.get(asset, 0.0) + w * actual_ret
                curr_holdings[asset] = 0
                stopped_assets.append(asset)
            else:
                ret = asset_daily_rets.loc[curr_date, asset]
                daily_pnl += w * ret
                asset_contribution[asset] = asset_contribution.get(asset, 0.0) + w * ret

        capital *= (1 + daily_pnl)
        nav_record.append({'date': curr_date, 'nav': capital})
        log_buffer_pnl.append(daily_pnl)

        if stopped_assets:
            logs.append(f"âš ï¸ [{curr_date.strftime('%Y-%m-%d')}] è§¦å‘æ­¢æŸ: {', '.join(stopped_assets)}")

        if len(log_buffer_pnl) == 5 or i == len(full_dates) - 1 or curr_date == end_date:
            cycle_ret = (np.prod([1 + r for r in log_buffer_pnl]) - 1)
            hold_str = ", ".join([f"{a}({w:.1%})" for a, w in curr_holdings.items() if w > 0])
            if not hold_str: hold_str = "ç©ºä»“"
            
            logs.append(f"Cycle {cycle_count:02d} | æ”¶ç›Š: {cycle_ret * 100:>+5.1f}% | å‡€å€¼: {capital:.4f} | æŒä»“: {hold_str}")
            logs.append("-" * 30)
            
            log_buffer_pnl = []
            cycle_count += 1
            if i < len(full_dates) - 1:
                log_start_date = full_dates[i + 1]

    return pd.DataFrame(nav_record), pd.DataFrame(list(asset_contribution.items()), columns=['Asset', 'Contribution']), logs


# ================= 4. UI é¡µé¢ =================

with st.sidebar:
    st.header("âš¡ Dual Momentum")
    
    # ç®€å•çš„è·¯å¾„æ˜¾ç¤ºï¼Œä¸å†æ˜¾ç¤ºå¤æ‚çš„ç¯å¢ƒè¯Šæ–­
    st.caption(f"å½“å‰æ•°æ®æº: `{DEFAULT_DATA_FOLDER}`")
    data_folder = st.text_input("æ•°æ®è·¯å¾„", value=DEFAULT_DATA_FOLDER)
    st.divider()

    st.subheader("ğŸ—“ï¸ æ ¸å¿ƒå‚æ•°")
    col_d1, col_d2 = st.columns(2)
    start_d_input = col_d1.date_input("å¼€å§‹æ—¥æœŸ", value=pd.to_datetime("2025-01-01"))
    end_d_input = col_d2.date_input("ç»“æŸæ—¥æœŸ", value=pd.to_datetime("2025-12-31"))

    hold_num_input = st.number_input("æŒä»“æ•°é‡", 1, 20, 5)
    stop_loss_pct = st.number_input("æ­¢æŸ (%)", 0.0, 20.0, 4.0, step=0.5) / 100.0

    with st.expander("ğŸ› ï¸ ç®—æ³•å‚æ•°"):
        lookback_short = st.number_input("çŸ­æœŸåŠ¨é‡", value=5)
        lookback_long = st.number_input("é•¿æœŸåŠ¨é‡", value=20)
        filter_ma = st.number_input("å‡çº¿è¿‡æ»¤", value=60)
        atr_window = st.number_input("ATRå‘¨æœŸ", value=20)

    run_btn = st.button("ğŸš€ è¿è¡Œç­–ç•¥", type="primary", use_container_width=True)

# ä¸»ç•Œé¢
st.title("Dual Momentum ç­–ç•¥å›æµ‹")

if run_btn:
    with st.spinner('æ­£åœ¨åŠ è½½æ•°æ®...'):
        # è°ƒç”¨æ—¶ä¸å†æ¥æ”¶ debug_info
        df_prices, df_vols, df_lows, err = load_data_and_calc_atr(data_folder, atr_window)
    
    if err:
        st.error(err)
    else:
        params = {
            'short': lookback_short, 'long': lookback_long, 'ma': filter_ma,
            'hold_num': hold_num_input, 'stop_loss_pct': stop_loss_pct,
            'start_date': start_d_input, 'end_date': end_d_input
        }

        with st.spinner('æ­£åœ¨è®¡ç®—ç­–ç•¥...'):
            res_nav, res_contrib, res_logs = run_strategy_logic(df_prices, df_vols, df_lows, params)

        if res_nav.empty:
            st.warning("æ— äº¤æ˜“æ•°æ®ã€‚")
        else:
            res_nav.set_index('date', inplace=True)
            res_contrib.sort_values('Contribution', ascending=False, inplace=True)

            total_ret = res_nav['nav'].iloc[-1] - 1
            days = (res_nav.index[-1] - res_nav.index[0]).days
            annual_ret = (1 + total_ret) ** (365 / days) - 1 if days > 0 else 0
            max_dd = (res_nav['nav'] / res_nav['nav'].cummax() - 1).min()
            
            daily_rets = res_nav['nav'].pct_change().fillna(0)
            sharpe = (daily_rets.mean() * 252) / (daily_rets.std() * np.sqrt(252)) if daily_rets.std() > 0 else 0

            st.success("å›æµ‹å®Œæˆï¼")
            
            k1, k2, k3, k4 = st.columns(4)
            k1.metric("æ€»æ”¶ç›Šç‡", f"{total_ret * 100:.2f}%", delta_color="normal")
            k2.metric("å¹´åŒ–æ”¶ç›Š", f"{annual_ret * 100:.2f}%")
            k3.metric("æœ€å¤§å›æ’¤", f"{max_dd * 100:.2f}%", delta_color="inverse")
            k4.metric("å¤æ™®æ¯”ç‡", f"{sharpe:.2f}")

            tab_chart, tab_attr, tab_log = st.tabs(["ğŸ“ˆ æ›²çº¿", "ğŸ† å½’å› ", "ğŸ“ æ—¥å¿—"])

            with tab_chart:
                fig = go.Figure()
                fig.add_trace(go.Scatter(
                    x=res_nav.index, y=(res_nav['nav'] - 1)*100,
                    mode='lines', name='æ”¶ç›Šç‡', line=dict(color='#ff7f0e', width=2)
                ))
                fig.update_layout(title='ç´¯è®¡æ”¶ç›Šç‡ (%)', margin=dict(l=10, r=10, t=40, b=10))
                st.plotly_chart(fig, use_container_width=True)

            with tab_attr:
                res_contrib['Color'] = res_contrib['Contribution'].apply(lambda x: 'red' if x >= 0 else 'green')
                fig_bar = px.bar(res_contrib, x='Contribution', y='Asset', orientation='h',
                                 text_auto='.2%', color='Contribution',
                                 color_continuous_scale=['green', '#f0f2f6', 'red'])
                fig_bar.update_layout(height=max(400, len(res_contrib) * 20), yaxis={'categoryorder': 'total ascending'})
                st.plotly_chart(fig_bar, use_container_width=True)

            with tab_log:
                st.text_area("äº¤æ˜“æ˜ç»†", "\n".join(res_logs), height=500)
else:
    st.info(f"ğŸ‘ˆ è¯·ç‚¹å‡»ã€è¿è¡Œç­–ç•¥ã€‘")

